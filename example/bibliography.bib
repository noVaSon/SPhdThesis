
@mastersthesis{correya_retrieving_2017,
	title = {Retrieving {Ambiguous} {Sounds} {Using} {Perceptual} {Timbral} {Attributes} in {Audio} {Production} {Environments}},
	abstract = {For over an decade, one of the well identified problem within audio production environments is the effective retrieval and management of sound libraries. Most of the self-recorded and commercially produced sound libraries are usually well structured in terms of meta-data and textual descriptions and thus allowing traditional text-based retrieval approaches to obtain satisfiable results. However, traditional information retrieval techniques pose limitations in retrieving ambiguous sound collections (ie. sounds with no identifiable origin, foley sounds, synthesized sound effects, abstract sounds) due to the difficulties in textual descriptions and the complex psychoacoustic nature of the sound. Early psychoacoustical studies propose perceptual acoustical qualities as an effective way of describing these category of sounds[1]. In Music Information Retrieval (MIR) studies, this problem were mostly studied and explored in context of content-based audio retrieval. However, we observed that most of the commercial available systems in the market neither integrated advanced content-based sound descriptions nor the visualization and interface design approaches evolved in the last years. Our research was mainly aimed to investigate two things; 1.development of audio retrieval system incorporating high level timbral features as search parameters. 2.Investigate user-centered approach in integrating these features into audio production pipelines using expert-user studies. In this project, We present an prototype which is similar to traditional sound browsers (list-based browsing) with an added functionality of filtering and ranking sounds by perceptual timbral features such as brightness, depth, roughness and hardness. Our main focus was on the retrieval process by timbral features. Inspiring from the recent focus on user-centered systems ([2], [3]) in the MIR community, in-depth interviews and qualitative evaluation of the system were conducted with expert-user in order to identify the underlying problems. Our studies observed the potential applications of high-level perceptual timbral features in audio production pipelines using a probe system and expert-user studies. We also outlined future guidelines and possible improvements to the system from the outcomes of this research.},
	author = {Correya, Albin Andrew},
	year = {2017},
	doi = {10.5281/zenodo.1098587},
	keywords = {freesound, Audio Production, AudioCommons, Content-Based Audio Retrieval, High-level Perceptual Timbral Features, Music Information Retrieval, Sound Browsers, Sound Databases, User study},
	file = {Correya - 2017 - Retrieving Ambiguous Sounds Using Perceptual Timbr.pdf:/Users/ericlehmann/Zotero/storage/R57CGRTA/Correya - 2017 - Retrieving Ambiguous Sounds Using Perceptual Timbr.pdf:application/pdf}
}

@book{cooper_about_2014,
	title = {About face: the essentials of interaction design},
	publisher = {John Wiley \& Sons},
	author = {Cooper, Alan and Reimann, Robert and Cronin, David and Noessel, Christopher},
	year = {2014},
	annote = {p265 cancel mechanism is critical p297 don't let users actions end in an error (immediate response) p243 design for three levels of Experience p29 Goal directed design bulletpoints pics p12 product succsess p23 goal directed design }
}

@article{bates_information_1979,
	title = {Information {Search} {Tactics}.},
	volume = {30},
	issn = {00028231},
	url = {http://search.ebscohost.com/login.aspx?direct=true&db=bth&AN=17236092&site=ehost-live},
	abstract = {As part of the study of human information search strategy, the concept of the search tactic, or move made to further a search, is introduced. Twenty-nine tactics are named, defined, and discussed in four categories: monitoring, file structure, search formulation, and term. Implications of the search tactics for research in search strategy are considered. The search tactics are intended to be practically useful in information searching. This approach to searching is designed to be general, yet nontrivial; it is applicable to both bibliographic and reference searches and in both manual and on-line systems. [ABSTRACT FROM AUTHOR]},
	number = {4},
	journal = {Journal of the American Society for Information Science},
	author = {Bates, Marcia J.},
	year = {1979},
	keywords = {Electronic information resources, Information resources, Information resources management, Information science, Information storage \& retrieval systems, Library resources},
	pages = {205 -- 214},
}

@inproceedings{heise_aurally_2009,
	title = {Aurally and visually enhanced audio search with soundtorch},
	booktitle = {{CHI}'09 {Extended} {Abstracts} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Heise, Sebastian and Hlatky, Michael and Loviscach, JÃ¶rn},
	year = {2009},
	pages = {3241--3246}
}


@phdthesis{bogdanov_music_2013,
	address = {Barcelona, Spain},
	type = {{PhD} {Thesis}},
	title = {From music similarity to music recommendation: {Computational} approaches based on audio features and metadata},
	url = {http://mtg.upf.edu/system/files/publications/dbogdanov_phd_thesis_2013_0.pdf},
	school = {Universitat Pompeu Fabra},
	author = {Bogdanov, Dmitry},
	month = sep,
	year = {2013},
	keywords = {music discovery, music information retrieval, music recommendation, music similarity, personalization, preference elicitation, recommender systems, user modeling, visualization},
}


@misc{virostek_paul_introduciton_2018,
	type = {Blog about field-recording},
	title = {An {Introduciton} to {Sound} {FX} {Metadata} {Apps} 2 - {Comparing} apps},
	shorttitle = {Comparing {Metadata} {Apps}},
	url = {https://www.creativefieldrecording.com/2014/06/17/an-introduction-to-sound-fx-metadata-apps-2-comparing-apps/},
	language = {English},
	urldate = {2018-11-01},
	author = {Virostek, Paul},
	month = nov,
	year = {2018}
}

@book{kim_mpeg-7_2006,
	title = {{MPEG}-7 audio and beyond: {Audio} content indexing and retrieval},
	publisher = {John Wiley \& Sons},
	author = {Kim, Hyoung-Gook and Moreau, Nicolas and Sikora, Thomas},
	year = {2006},
	file = {Kim et al. - 2006 - MPEG-7 audio and beyond Audio content indexing an.pdf:/Users/ericlehmann/Zotero/storage/X9LMF7NT/Kim et al. - 2006 - MPEG-7 audio and beyond Audio content indexing an.pdf:application/pdf}
}
